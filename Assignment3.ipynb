{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Classification using Images of Faces\n",
    "#### By Ann Joseph (251061872) Meher Pooja Pranavi Punyamanthula (251056788)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a private kaggle dataset consisting of about 28,000 rows and 2 columns. The two columns are \"label\" and \"features\". The \"features\" column consist of pixels that make is a 48x48 grayscale image and the \"label\" column is a number from 0 to 6 depending on how this grayscale image was classified where:\n",
    "0 - Angry\n",
    "1 - Disgust\n",
    "2 - Fear\n",
    "3 - Happy\n",
    "4 - Sad\n",
    "5 - Surprise\n",
    "6 - Neutral\n",
    "\n",
    "In this assignment, we built a Convolutional Neural Network (CNN) to classify images in our test data and compared it with the its real labels to obtain an accucary for our CNN.\n",
    "\n",
    "The following are the steps we did in this assignment:\n",
    "1. Importing Data\n",
    "2. Image visualization\n",
    "3. Data Preprocessing\n",
    "4. Reshaping the data\n",
    "5. Data Splitting\n",
    "6. Building the CNN\n",
    "7. Model Training\n",
    "8. Prediction using the Test Set\n",
    "\n",
    "## 1. Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "import keras as ks\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import imshow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from PIL import Image\n",
    "#from __future__ import print_function\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filname='sentiment_data.csv'\n",
    "label_map = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Image visualization\n",
    "Below is a list of the labels of the first 10 images in our dataset and what the grayscale images actually look like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels= {0:\"angry\", 1:\"disgust\", 2:\"fear\", 3:\"happy\", 4:\"sad\", 5:\"surprise\", 6:\"neutral\"}\n",
    "images=[]\n",
    "for image_pixels in data.iloc[1:11,1]:\n",
    "    image_string = image_pixels.split(',') #pixels are separated by commas.\n",
    "    image_data = np.asarray(image_string, dtype=np.uint8).reshape(48,48)\n",
    "    img = Image.fromarray(image_data)\n",
    "    images.append(img)\n",
    "#imshow(np.asarray(img))\n",
    "#print(data.iloc[1,0])\n",
    "\n",
    "for ima in images:\n",
    "    plt.figure()\n",
    "    plt.imshow(np.asarray(ima))\n",
    "for label in data.iloc[1:11,0]:\n",
    "    print(labels[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "Since the pixels in our data were given as a single string, we define a function below to split this string into a list of pixels for each image in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(filname):\n",
    "    # images are 48x48\n",
    "    # N = 35887\n",
    "    Y = []\n",
    "    X = []\n",
    "    first = True\n",
    "    for line in open(filname):\n",
    "        if first:\n",
    "            first = False\n",
    "        else:\n",
    "            row = line.split(',')\n",
    "\n",
    "            Y.append(int(row[0]))\n",
    "\n",
    "            X.append([int(p) for p in row[1].split()])\n",
    "\n",
    "    X, Y = np.array(X) / 255.0, np.array(Y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = getData(filname)\n",
    "num_class = len(set(Y))\n",
    "\n",
    "# To see number of training data point available for each label\n",
    "def balance_class(Y):\n",
    "    num_class = set(Y)\n",
    "    count_class = {}\n",
    "    for i in range(len(num_class)):\n",
    "        count_class[i] = sum([1 for y in Y if y == i])\n",
    "    return count_class\n",
    "balance = balance_class(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Reshaping the data\n",
    "Since we now have a list of pixels for each image of our dataset, we have to take those pixels and reshape it into a 48x48 matrix so that it represents a 48x48 grayscale image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras with tensorflow backend\n",
    "N, D = X.shape\n",
    "X = X.reshape(N, 48, 48, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Splitting\n",
    "Since this dataset is large with around 28,000 rows, we will be splitting the data into 3 sets: a training set, a validation set and a test set in the ratio 80:10:10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=0)\n",
    "y_train = (np.arange(num_class) == y_train[:, None]).astype(np.float32)\n",
    "y_test = (np.arange(num_class) == y_test[:, None]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Building the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Activation , Dropout ,Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.models import model_from_json\n",
    "from keras.optimizers import *\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "batch_size = 128\n",
    "epochs = 124"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build our CNN, below we define a function that specifies 4 layers. As you can see, we have used the Rectified Linear Unit or ReLU as our activation function in this classification and the Max Pooling method to resize images before they are inputted to the next layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main CNN model with four Convolution layer & two fully connected layer\n",
    "def baseline_model():\n",
    "    # Initialising the CNN\n",
    "    model = Sequential()\n",
    "    # 1 - Convolution\n",
    "    model.add(Conv2D(64,(3,3), border_mode='same', input_shape=(48, 48,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    # 2nd Convolution layer\n",
    "    model.add(Conv2D(128,(5,5), border_mode='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    # 3rd Convolution layer\n",
    "    model.add(Conv2D(512,(3,3), border_mode='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    # 4th Convolution layer\n",
    "    model.add(Conv2D(512,(3,3), border_mode='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    # Flattening\n",
    "    model.add(Flatten())\n",
    "    # Fully connected layer 1st layer\n",
    "    model.add(Dense(256))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    # Fully connected layer 2nd layer\n",
    "    model.add(Dense(512))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(num_class, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[categorical_accuracy])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a function to calculate weights in the CNN and a final CNN model with all weights initialised is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model_saved():\n",
    "    #load json and create model\n",
    "    json_file = open('model_4layer_2_2_pool.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(loaded_model_json)\n",
    "    #load weights from h5 file\n",
    "    model.load_weights(\"model_4layer_2_2_pool.h5\")\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[categorical_accuracy])\n",
    "    return model\n",
    "is_model_saved = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Training\n",
    "The final CNN model is then train using the validation set as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model from disk\n"
     ]
    }
   ],
   "source": [
    "if(is_model_saved==False ):\n",
    "    # Train model\n",
    "    model = baseline_model()\n",
    "    # Note : 3259 samples is used as validation data &   28,709  as training samples\n",
    "    model.fit(X_train, y_train,\n",
    "                batch_size=batch_size,epochs=epochs,verbose=2,validation_split=0.1111)\n",
    "    model_json = model.to_json()\n",
    "    with open(\"model_4layer_2_2_pool.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(\"model_4layer_2_2_pool.h5\")\n",
    "    print(\"Saved model to disk\")\n",
    "\n",
    "else:\n",
    "    # Load the trained model\n",
    "    print(\"Load model from disk\")\n",
    "    model = baseline_model_saved()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Prediction using the Test Set\n",
    "Finally, the CNN is used to classify images in the test set and the accuracy is calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 512)       590336    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 3591      \n",
      "=================================================================\n",
      "Total params: 4,478,727\n",
      "Trainable params: 4,474,759\n",
      "Non-trainable params: 3,968\n",
      "_________________________________________________________________\n",
      "None\n",
      " Accuracy on Test set :  0.8596307906652734\n"
     ]
    }
   ],
   "source": [
    "# Model will predict the probability values for 7 labels for a test image\n",
    "score = model.predict(X_test)\n",
    "print (model.summary())\n",
    "new_X = [ np.argmax(item) for item in score ]\n",
    "y_test2 = [ np.argmax(item) for item in y_test]\n",
    "# Calculating categorical accuracy taking label having highest probability\n",
    "accuracy = [ (x==y) for x,y in zip(new_X,y_test2) ]\n",
    "print(\" Accuracy on Test set : \" , np.mean(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
